一、隔离级别
   1.查看隔离级别
       旧版本： select @@global.tx_isolation;
       新版本： select @@global.transaction_isolation;
   2.设置隔离级别
       set global transaction_isolation ='read-committed';
       set global transaction_isolation ='repeatable-read';


二、锁(id设置为了主键、隔离级别为repeatable-read)
   1.排它锁-事务A中执行以下语句锁定某一行记录
       如果列不是唯一锁引，则行锁变成临间锁

       select * from wjx_test_copy where id = 11000098 for update;
       A事务提交之前
         1.1其它事务不能修改这一行记录(会阻塞)，但可查询这一行记录
         1.2其它事务不能再对这行进行for update加锁(会阻塞)

   2.排它锁-事务A中执行以下语句锁定多行记录(明确几行)
       select * from wjx_test_copy where id in(11000098,11000097) for update;
       A事务提交之前
         2.1其它事务不能修改这多行(其中任意一行)记录(会阻塞)，但可查询这多行(任意一行)记录
         2.2其它事务不能再对这多行(其中的任意一行)进行for update加锁(会阻塞)

   3.排它锁-事务A中执行以下语句锁定多行记录（范围）
          select * from wjx_test_copy where id > 11000097 for update;
          A事务提交之前
            3.1其它事务不能修改这多行(其中任意一行)记录(会阻塞)，但可查询这多行(任意一行)记录
            3.2其它事务不能再对这多行(其中的任意一行)进行for update加锁(会阻塞)
            3.3A事务可以插入满足条件的记录中还不存在的主键(然后修改)，其他事务不可以插入满足条件的记录中还不存在的主键(会阻塞，因为A事务加了间隙锁,使用between and 也会加间隙锁)

   4.共享锁-事务A中执行以下语句锁定某行记录
       select * from wjx_test_copy where id = 11000123 lock in share mode;
       A事务提交之前
         4.1A事务自己可以修改这行记录(此时其它事务没有对该行加共享锁且也能不修改此行数据，会阻塞--lock in share mode)
         4.2A事务自己不可以修改这行记录，会阻塞(此时其它事务也对该行加了共享锁且也不能修改此行数据，会阻塞--lock in share mode)
         4.3其它事务也对该行加了共享锁，然后，A事务先对该行做更新操作（会阻塞），其它事务对该行做更新操作时，其他事务会检测到死锁并回
            滚其它事务且A事务不再阻塞立刻执行，其它事务中抛出的死锁信息如下
            Deadlock found when trying to get lock; try restarting transaction
   5.普通select词句默认不加锁，增、删、改默认加排它锁(行锁)
   6.行锁默认超时时间为50秒
   7.表锁
     7.1事务A中执行以下语句对表加读锁，A事务不能对表进行写操作(直接报错)。释放读锁之前，其他事务不能对该表进行插入、更新、删除操作(会阻塞)，可以进行查询操作
        lock table wjx_test_copy read;

     7.2事务A中执行以下语句对表加写锁(A事务可读可写)，释放写锁之前，其他事务不能对该表进行查询、插入、更新、删除操作(会阻塞)
        lock table wjx_test_copy write;

     7.3释放表锁(读、写锁)
        unlock tables;

     7.4查看表的上锁情况,In_user字段的值为1表示有上锁，为0则表示没有上锁
        show open tables;


三、MVCC(多版本并发控制)
   1.目的：解决读写冲突
   2.Read View：事务进行快照读时产生的读视图（快照读那一刻数据库系统的快照），记录并维护系统当前活跃事务(没有提交的事务)的ID，细分为
                三个属性，分别为活跃事务id列表、最小事务id、未分配的最新事务id加1的值
   3.实现： 每一行两个隐藏字段（6个字节的事务id、7个字节的回滚指针）+ undo log


四、锁引
    1.复合锁引，如有锁引index(C1,C2,C3)
    复合锁引能解决回表问题（二次查询问题）?
        因为如果复合索引已覆盖了查询，则不会再通过主键去（聚集锁引）查询数据。
        select C1,C2,C3 from tableName;

    如果查询中有某个锁引列的范围查询，则其右边所有的列都无法使用到锁引。以下查询只能使用到锁引的前两列(C1、C2)
    select * from tableName where C1 = "XX" and C2 like "Y%" and C3 = "ZZ";

    不能跳过锁引中的列。以下查询只能用到锁引中的第一列(C1)
    select * from tableName where C1 = "XX" and C3 = "ZZ";

    2.对于BLOB、TEXT或者很长的varchar类型的列，必须使用前缀锁引，mysql不允许使用这些列的完整长度。

    3.前缀锁引，前缀锁引不能做order by 、group by，也无法做覆盖扫描
      如何计算前缀锁引的长度？
      3.1 不断调整前缀列的选择性，使之接近完整列的选择性

         首先通过以下语句查看完整列的选择性(统计字段重复次数)
         select count(*) c,name from tableName group by name order by c desc limit 10

         然后通过以下语句不断调整前缀列的选择性，使之接近完整列的选择性(出现的次基本一致)。最终x的值就是锁引前缀长度。
         select count(*) c,left(name,x) from tableName group by name order by c desc limit 10

      3.2 计算完整列的选择性
         select count(distinct name)/count(*) from tableName;

         然后通过以下语句计算各前缀列的选择性，与完整列的选择性基本一致即可
         select
              count(distinct left(name,3)/count(*) c1,
              count(distinct left(name,4)/count(*) c2,
              count(distinct left(name,5)/count(*) c3,
              count(distinct left(name,6)/count(*) c4,
              count(distinct left(name,7)/count(*) c5
         from tableName;

    4.只有当复合锁引的列顺序和order by子句的顺序完全一致，并且所有列的排序方向一样时，mysql才能使用该复合锁引来排序。
      order by 也需要满足最左前缀匹配规则。

    5.可以使用以下命令查看表是否损坏（损坏的锁引会导致查询返回错误的结果或者莫须有的主键冲突问题，严重时会导致数据库崩溃）
      check table wjx_test_copy;

      可以使用命令来修复损坏的表，Inodb引擎不支持？？？
      repair table wjx_test_copy;


五、查询性能优化
    1.切分查询，一个大查询分成多个小查询，每个小查询只返回一部分结果
    2.分解关联查询，将几个表的一次关联查询分解成多个单表查询，然后在应用程序中进行合并结果
      提高缓存效率、执行单个查询可以减少锁竞争，在应用层做关联可以更容易对数据进行拆分(更容易做到高性能和高扩展)
    3.表的关联顺序不一定是sql语句中写的顺序，优化器可以决定表的关联顺序。
      将外连接转化成内连接，where条件、库表结构都可能让外连接等价于一个内连接，mysql能识别这一点并重写查询。
    4.覆盖锁引扫描：当锁引中的列包含所有查询中需要使用列的时候，就可以直接使用锁引返回数据，不需要查询具体的数据行。
    5.提前终止查询：
        5.1发现已经满足查询需求时，立刻终止查询（例如使用limit）
        5.2发现一个不成立的条件时立刻返回空结果。id为主键，执行以下语句则立刻终止查询并返回空结果
           select * from wjx_test where id = -1;

           执行计划中的Extra字段的信息可证明这一点
           no matching row in const table
    6.hint提示(告诉执行优化器，按照我们定义的方式来生成执行计划)
        6.1只使用字段FIELD1上的锁引，不使用其它字段上的锁引
           SELECT * FROM TABLE1 FORCE INDEX (FIELD1)

        6.2优先操作(HIGH_PRIORITY用于select和insert中)
           select HIGH_PRIORITY * from wjx_test where id = 312;

        6.3滞后操作(LOW_PRIORITY用于insert和update中)
           update LOW_PRIORITY table1 set field1= where field1=xx

    7.count()的作用
      统计某个列值的数量(不统计NULL列)、统计行数
      7.1 count(*) 忽略所有的列，而直接统计所有的行数。在括号内指定了一个列却希望统计结果集的行数，这是不对的。

    8.当order by、group by表达式中的列只涉及到一个表中的列时，才能使用到锁引
    9.子查询尽可能使用关联查询来替代
    10.在分组的基础上再做聚合操作是不够优化的，怎么办？最好的办法返回更多的数据，在应用程序中处理
       select name,sum(sal) from wjx_test GROUP BY name with rollup;
    11.使用用户自定义变量（用来存储内容的临时容器，在连接mysql的整个过程中都存在，即一个连接中有效，在查询中混合使用过程化和关系化的逻辑时非常有用）
        set @name:="楚楚";
        select * from wjx_test_copy where name = @name;

        在任何类型的sql中都可以对变量进行赋值
        使用自定义变量无法使用查询缓存
        赋值符号:=的优先级非常低，所以赋值表达式应该使用明确的括号

    12.避免重复查询刚刚更新的数据
       场景：更新行的同时又希望获得该行的信息（例如，更新某个字段后又要获取该字段），怎么办？
       12.1 两条sql，一个更新一个查询
       12.2 使用变量,因为第二条sql不用访问任何数据表，所以快很多(如果网络延迟非常大，则这个优化意义可能不大)。第一条sql测试的时候为什么执行不成功呢（更新行数0行）
            update wjx_test_copy set name = "天下第一" where id = 11000158 and @v_name := "天下第一";
            select @v_name;
    13.查询缓存在8.0版本已经删除了，因为查询缓存 缓存的是查询结果（与缓存执行计划不一样），另在增、删、改的时候又要清除缓存，反倒是影响性能
    14.QPS、TPS的区别，吞吐量
       QPS为query Per Second的缩写，指数据库每秒可以处理多少个请求(一般来说一个请求就是一条SQL语句)
       TPS为Transaction Per Second的缩写，指数据库每秒处理的事务数量（每秒处理多少次事务的提交、回滚）
       吞吐量：机器的磁盘存储每秒可以读写多少字节的数据量
    15.CPU负载含义，以4核CPU为例
       负载为0.15则一个核都没有用满
       负载为1则其中一个核基本用满，其它三个核比较空闲
       负载为4则4个核基本都用满了
       负载为6则4个核基本都用满了，很多进程可能在等待CPU执行自己的任务


六、mysql客户端/服务端通信协议
   1.mysql客户端和服务端通信协议是半双工的，在任何一个时刻，要么是由客户端向服务端发送数据，要么是由服务端向客户端发送数据，这两个动作不能同时发生
   2.执行以下命令，可查看mysql连接或线程的状态(Command列表示状态)
     show full processlist;


七、分区,一个独立的逻辑表，底层由多个物理子表组成
    1.目的：将数据按照一个较粗的粒度分布在不同的表中
    2.一个表最多只能有1024个分区、分区表无法使用外键
    3.分区列和索引列不匹配时，会导致查询无法进行分区过滤。应避免建立和分区不匹配的索引。
    4.所有分区都必须使用相同的存储引擎。有的存储引擎不支持分区。
    5.在where条件中带上分区的列(即使无用也要带上)，这样优化器能够过滤掉无须访问的分区
    6.不能对分区列进行计算或使用函数，否则不能过滤分区


八、视图，虚拟表，不存任何数据，它返回的数据是从其他表中生成的
    1.创建并查询视图
      create view wjx_test_copy_view as select * from wjx_test_copy where id > 11000155;
      select * from wjx_test_copy_view;

    2.更新视图(实际表中也会被更新)
      update wjx_test_copy_view set name = "天下第三" where id = 11000158;

    3.视图的实现方式
      3.1临时表，存在性能问题
      3.2重写含有视图的查询，即将视图的定义sql直接包含进查询的sql中

    4.mysql不支持在视图中创建锁引

九、在mysql内部存储代码
   1.mysql可以通过触发器、存储过程、存储函数、事件(定时任务)来存储代码，是一种共享和复用代码的方法
   2.InooDB引擎中，原操作和触发器操作是在同一个事务中。触发器可用于系统维护任务、更新反范式化数据。只支持基于行的触发。
   3.创建事件，每分钟执行一次插入语句
     create event wjx_event on schedule every 1 minute
     do
     INSERT INTO `mall_v2.8.1`.`wjx_test_copy`(`sal`, `name`, `full_name`, `sex`) VALUES (3.58, '天下第三123', 'weilaifullname', '男');

   4.停止/开启事件
     set global event_scheduler=0/1;
     set global event_scheduler=OFF/ON;

     ALTER EVENT wjx_event ON COMPLETION PRESERVE DISABLE;

   5.可在系统表中查看事件的状态
     select * from information_schema.`EVENTS`

   6.事件调度是单独一个线程，但每次会创建一个新线程来执行事件，执行完成后，该执行线程就会被销毁

十、服务器设置
   1.配置文件的位置，在类NNIX系统中，配置文件位置一般在/etc/my.cnf ，可通过以下命令查找文件
     find / -name "my.cnf"

   2.配置文件分为很多个部分，每个部分的开头是一个用方括号括起来的分段名称，服务器通常读取mysqld这一段，客户端程序读取client这一段，
     一定要确认放到了正确的分段中，否则配置不生效


十一、操作系统和硬件优化
   1.如果负担的起，增加内存是解决随机IO最好的办法

十二、执行SQL语句的流程(以更新sql为例)
     update tableName set name="zhangsan" where id =1
     客户端通过数据库连接发送执行sql请求->mysql服务器开启线程接收请求并交给SQL接口组件处理->查询解析器解析sql（知道这个sql是做什么的）->查询优化器(怎么执行才算最优、生成执行计划)->
     执行器(调用存储引擎接口执行 执行计划)->存储引擎会把id等于1的这条数据加载到存储引擎的缓冲池并加独占锁，然后写undo日志（直接把更改之前的数据写入到磁盘undo日志文件）->更新存储引擎缓冲池中id等于1的数据->
     把更新后的数据存到redo日志缓冲区中(还没到磁盘)->提交事务时，根据刷盘策略将redo日志缓冲区中的数据存储到磁盘(同时binlog日志也会刷到磁盘，什么时候记录的？)->若MySQL的配置项innodb_flush_log_at_trx_commit的值为0，则不刷到磁盘。
     若值为1，则直接刷到磁盘中的redo日志文件(存储引擎缓冲池中的数据刷到磁盘前，Mysql宕机，则可用此日志来恢复修改数据,建议设置为1，因为设置1时数据是不会丢失的，其它两种都存在数据丢失的情况)。
     若值为2，则先把redo日志缓冲区中的数据刷到操作系统缓冲区，过一段时间再刷到磁盘中的redo日志文件->把本次更新的binlog日志文件的名字和更新binlog日志文件的位置都写到redo日志文件中，还会在
     redo日志文件中写入commmit标记(有了此标记，事务才算提交成功，commit标记用于保持两个日志文件的数据一致性)->完成事务提交。

     binlog日志刷盘策略：sync_binlog的值为0(也是默认值)时，写到操作系统缓冲区，为1时则直接写到磁盘。

十三、数据库压测
     1.sysbench工具
     2.压测过程中查看各指标的负载情况
       2.1使用top命令查看CPU、内存的负载情况
       2.2使用dstat -d命令查看磁盘IO的负载情况，结果列表中的read和writ列，分别表示IO吞吐量每秒读取多少B的数据、每秒写入多少kb的数据（参照：普通的机械硬盘可以做到每秒上百MB的读写数量）
           -dsk/total-
            read  writ
            454B   30k
              0    12k

          dstat -r命令，分别表示读IOPS和写IOPS，即随机磁盘每秒读、写多少次(参照：一般可以达到两三百)
             --io/total-
              read  writ
             0.01  1.46
                0     0

          dstat -n命令，查看网卡的流量情况，每秒钟网卡接收到的流量、通过网卡发送出去的流量分别是多少(参照：千兆网卡，每秒总流量在100M左右)
            -net/total-
             recv  send
               0     0
              46k   26k

十四、生产环境数据库的可视化监控平台搭建，基于Prometheus(采集和存储数据)+Grafana(展示数据)。可以用来监控Java系统、中间件系统。
     1.下载包，以下两个分别是监控系统、采集数据库所在机器的CPU、内存、磁盘、网络等数据
       wget http://cactifans.hi-www.com/prometheus/prometheus-2.14.0.linux-amd64.tar.gz
       wget http://cactifans.hi-www.com/prometheus/node_exporter-0.18.0.linux-amd64.tar.gz

       以下包用于采集mysql数据库自己的监控数据，比哪sql性能、连接数量之类
       https://github.com/prometheus/mysqld_exporter/releases路径下载mysqld_exporter-0.13.0.linux-amd64.tar.gz并上传至linux服务器

     2.解压包，wjx目录下创建目录prometheus-export-data、prometheus-export-root，然后分别执行以下命令
       tar xvf prometheus-2.14.0.linux-amd64.tar.gz -C ./prometheus-export-data
       tar xf node_exporter-0.18.0.linux-amd64.tar.gz -C ./prometheus-export-root
       tar xf mysqld_exporter-0.13.0.linux-amd64.tar.gz -C ./prometheus-export-root

     3.启动prometheus
       ./prometheus --storage.tsdb.retention=30d &

     4.浏览器访问prometheus
       http://192.168.1.88:9090

     5.下载、解压Grafana
       wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.6.3.linux-x64.tar.gz
       tar xf grafana-4.6.3.linux-x64.tar.gz -C ./prometheus-export-data

     6.启动Grafana，/usr/wjx/prometheus-export-data/grafana-4.6.3目录执行以下命令
       ./bin/grafana-server &

     7.浏览器访问Grafana，输入默认账号/密码(admin/admin)登录
       http://192.168.1.88:3000

       在config tab页签配置以下信息(其它使用默认信息)，Grafana就会自动从Prometheus里获取监控数据并展示
       名字输入 Prometheus、类型选择Prometheus、URL输入http://127.0.0.1:9090

     8.下载解压安装Grafana的仪表盘组件
       https://github.com/percona/grafana-dashboards/archive/v1.6.1.tar.gz
       tar xvf grafana-dashboards-1.6.1.tar.gz

       /usr/wjx/grafana-dashboards-1.6.1目录下执行以下命令进行安装(会生成大量的json文件，对应各种仪表盘)
       updatedb
       locate json |grep dashboards/

     9.在Grafana管理页面添加各种仪表盘(json文件，需要把linux服务器上的json文件下载到本地-通过WinScp等工具)，然后就能查看各种图表
       单击左上角齿轮->Dashboards->Import->上传json文件

     10.添加Prometheus对MySQL机器的监控
        10.1解压和启动node_exporter(自动采集这台linux机器上的CPU、磁盘、内存、网络之类的各种监控数据)
            tar xf node_exporter-0.18.0.linux-amd64.tar.gz

            /usr/wjx/node_exporter-0.18.0.linux-amd64目录下执行以下命令启动node_exporter
            nohup ./node_exporter &
        10.2Prometheus加入对机器的监控
            在/usr/wjx/prometheus-export-data/prometheus-2.14.0.linux-amd64目录下新增并配置host.yml文件（ClassPath目录下的host.yml文件）

            接着Prometheus就会跟MySQL机器上部署的node_exporter进行通信，源源不断的获取到这台机器的监控数据，写入自己的时序数据库中进行存储。
            接着我们就可以打开Grafana的页面，此时你就可以看到这台机器的相关性能监控了。

     11.启动mysqld_exporter组件(采集MySQL数据库自己的一些监控数据)
        省略，详见第10个pdf文档



























